{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Product Proposal - Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "\n",
    "@author: jl-datascientist (Jérémy Lecourt)\n",
    "\n",
    "Objectif:\n",
    "Système avancé de recommandation de produits afin d'effectuer des propositions personnalisées selon les profils des clients.\n",
    "\n",
    "Cadre du projet:\n",
    "Application pour élaborer une proposition personnalisée de Films adaptée selon les profils des individus, en utilisant un jeux de données obtenus depuis le site Imdb.com, plus grand recueil de films/notations utilisateurs sur la toile.\n",
    "\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPE 4 : Advanced modelisation and optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Import dataset and advanced filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>867989</td>\n",
       "      <td>107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1397338073</td>\n",
       "      <td>2014-04-12 21:27:53</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>867989</td>\n",
       "      <td>133</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1397182851</td>\n",
       "      <td>2014-04-11 02:20:51</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>867989</td>\n",
       "      <td>136</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1415635425</td>\n",
       "      <td>2014-11-10 16:03:45</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>867989</td>\n",
       "      <td>215</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1419568797</td>\n",
       "      <td>2014-12-26 04:39:57</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>867989</td>\n",
       "      <td>285</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1392514571</td>\n",
       "      <td>2014-02-16 01:36:11</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId originalTitle  averageRating  numVotes  userId  rating   timestamp  \\\n",
       "0        1     Toy Story            8.3    867989     107     4.0  1397338073   \n",
       "1        1     Toy Story            8.3    867989     133     4.0  1397182851   \n",
       "2        1     Toy Story            8.3    867989     136     5.0  1415635425   \n",
       "3        1     Toy Story            8.3    867989     215     2.0  1419568797   \n",
       "4        1     Toy Story            8.3    867989     285     2.5  1392514571   \n",
       "\n",
       "           date_rating  year  \n",
       "0  2014-04-12 21:27:53  2014  \n",
       "1  2014-04-11 02:20:51  2014  \n",
       "2  2014-11-10 16:03:45  2014  \n",
       "3  2014-12-26 04:39:57  2014  \n",
       "4  2014-02-16 01:36:11  2014  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import des données de notations à partir du Dataset constitué en ETAPE 1\n",
    "# Ajout d'un filtre temporel suite à la DataVisualisation effectuée en ETAPE 2\n",
    "# Le Dataset est filtré sur l'année 2014, dernière année complète disponible dans le jeux de données\n",
    "# Cela permet d'obtenir un Dataset cohérent, à jour, et de taille adéquate : de l'ordre de 10^5 ratings\n",
    "\n",
    "data_r = pd.read_csv(r\"Dataset\\data_t0.csv\")\n",
    "data_r.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb Ratings :  290101\n",
      "Nb Users :  5844\n",
      "Nb Movies :  5144\n",
      "Sparsity :  99.0 % \n",
      "\n",
      "Stats Ratings:\n",
      "\n",
      " count    290101.000000\n",
      "mean          3.569781\n",
      "std           1.043957\n",
      "min           0.500000\n",
      "25%           3.000000\n",
      "50%           4.000000\n",
      "75%           4.500000\n",
      "max           5.000000\n",
      "Name: rating, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyse du dataset en vue de modéliser un Recommender System\n",
    "\n",
    "Nb_ratings = len(data_r)\n",
    "Nb_users = len(data_r.groupby('userId'))\n",
    "Nb_movies = len(data_r.groupby('movieId'))\n",
    "\n",
    "print(\"Nb Ratings : \", Nb_ratings)\n",
    "print(\"Nb Users : \", Nb_users)\n",
    "print(\"Nb Movies : \", Nb_movies)\n",
    "print(\"Sparsity : \", round(1 - Nb_ratings /(Nb_users*Nb_movies),3)*100, \"%\", \"\\n\")\n",
    "\n",
    "#print(\"Stats Nb ratings per user:\\n\\n\", data_r['userId'].value_counts().describe(), \"\\n\")\n",
    "#print(\"Stats Nb ratings per movie:\\n\\n\", data_r['movieId'].value_counts().describe(), \"\\n\")\n",
    "print(\"Stats Ratings:\\n\\n\", data_r['rating'].describe(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290101, 10)\n",
      "(279353, 10)\n"
     ]
    }
   ],
   "source": [
    "# Data filtering (=> Reduct Sparsity = 99%): \n",
    "# On peut écarter les films très peu populaires et les clients trop occasionnels, qui n'apportent pas d'intérêt particulier\n",
    "# Cela permet d'éviter les données pour lesquels une prédiction correcte est très difficile voire complètement illusoire, et d'éliminer un biais potentiel\n",
    "# Avec un filtre raisonnable sur l'axe client et produit, on s'attend à réduire la dispersion de la donnée (sparsity improvement)\n",
    "\n",
    "rates_f0 = data_r.copy()\n",
    "\n",
    "# -> Filter to get sufficient number of Votes per userId (=> 15 minimum)\n",
    "\n",
    "Filter_User = rates_f0.groupby('userId')['movieId'].count().reset_index()\n",
    "Filter_User.columns = ['userId', 'nbMovie']\n",
    "\n",
    "rates_f0 = rates_f0.merge(Filter_User)\n",
    "print(rates_f0.shape)\n",
    "\n",
    "rates_f1 = rates_f0[rates_f0['nbMovie']>=15]\n",
    "#rates_f1 = rates_f1[rates_f1['nbMovie']<=100]\n",
    "print(rates_f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279353, 11)\n",
      "(210582, 11)\n"
     ]
    }
   ],
   "source": [
    "# -> Filter to get sufficient number of Votes per MovieId (=> 100 minimum)\n",
    "\n",
    "Filter_Movie = rates_f1.groupby('movieId')['userId'].count().reset_index()\n",
    "Filter_Movie.columns = ['movieId', 'nbUser']\n",
    "\n",
    "rates_f1 = rates_f1.merge(Filter_Movie)\n",
    "print(rates_f1.shape)\n",
    "\n",
    "rates_f2 = rates_f1[rates_f1['nbUser']>=100]\n",
    "#rates_f2 = rates_f2[rates_f2['nbUser']<=100]\n",
    "\n",
    "print(rates_f2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210582, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> Drop filter columns\n",
    "data_r = rates_f2.iloc[:,:8]\n",
    "data_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb Ratings :  210582\n",
      "Nb Users :  3929\n",
      "Nb Movies :  695\n",
      "Sparsity :  92.30000000000001 % \n",
      "\n",
      "Stats Ratings:\n",
      "\n",
      " count    210582.000000\n",
      "mean          3.678605\n",
      "std           1.004736\n",
      "min           0.500000\n",
      "25%           3.000000\n",
      "50%           4.000000\n",
      "75%           4.500000\n",
      "max           5.000000\n",
      "Name: rating, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyse du dataset filtré en vue de modéliser un Recommender System\n",
    "\n",
    "Nb_ratings = len(data_r)\n",
    "Nb_users = len(data_r.groupby('userId'))\n",
    "Nb_movies = len(data_r.groupby('movieId'))\n",
    "print(\"Nb Ratings : \", Nb_ratings)\n",
    "print(\"Nb Users : \", Nb_users)\n",
    "print(\"Nb Movies : \", Nb_movies)\n",
    "print(\"Sparsity : \", round(1 - Nb_ratings /(Nb_users*Nb_movies),3)*100, \"%\", \"\\n\")\n",
    "\n",
    "#print(\"Stats Nb ratings per user:\\n\\n\", data_r['userId'].value_counts().describe(), \"\\n\")\n",
    "#print(\"Stats Nb ratings per movie:\\n\\n\", data_r['movieId'].value_counts().describe(), \"\\n\")\n",
    "print(\"Stats Ratings:\\n\\n\", data_r['rating'].describe(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_0 = []\n",
    "#l_10 = []\n",
    "\n",
    "#for i in list(data_r['userId'].value_counts()):\n",
    "#    if i >= 10:\n",
    "#        l_10.append(i)\n",
    "#    else:\n",
    "#        l_0.append(i)\n",
    "#print(round(len(l_0)/len(l_10)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210582, 3)\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du dataset obtenu pour la modélisation\n",
    "df = pd.DataFrame(data = data_r[['movieId','userId','rating']])\n",
    "df.to_csv(r'Dataset\\data_t0f.csv', index = False)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un Dataset prêt pour l'entrainement et l'évaluation des modèles, avec une taille d'environ 210 000 notes utilisateurs, avec 695 films et 3929 utilisateurs, soit une dispersion de la donnée réduite à 92,3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Modélisations retenues et premières évaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210582, 3) <surprise.dataset.DatasetAutoFolds object at 0x00000137E35DAEB0>\n",
      "Longueur Testset: 52646\n"
     ]
    }
   ],
   "source": [
    "# Chargement du Dataset en utilisant la classe \"Surprise\" appropriée\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "df = pd.read_csv(r\"Dataset\\data_t0f.csv\")\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df, reader)\n",
    "\n",
    "print(df.shape, data)\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "print('Longueur Testset:',len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des modèles retenus\n",
    "\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import SVD\n",
    "\n",
    "algo_NP = NormalPredictor()           #Normal distribution approach\n",
    "\n",
    "sim_opt_I = {\"user_based\": False}     #Item-based with KNN approach\n",
    "algo_KNN_I = KNNBasic(sim_options=sim_opt_I)\n",
    "\n",
    "sim_opt_U = {\"user_based\": True}      #User-based with KNN approach\n",
    "algo_KNN_U = KNNBasic(sim_options=sim_opt_U)\n",
    "\n",
    "algo_SVD = SVD()                      #Matrix factorisation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NormalPredictor...\n",
      "\n",
      " KNN Item-based...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      " KNN User-based...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      " SVD...\n",
      "\n",
      " Fin entraînement!\n"
     ]
    }
   ],
   "source": [
    "# Entraînement des modèles\n",
    "\n",
    "print('\\n','NormalPredictor...')\n",
    "algo_NP.fit(trainset)\n",
    "\n",
    "print('\\n','KNN Item-based...')\n",
    "algo_KNN_I.fit(trainset)\n",
    "\n",
    "print('\\n','KNN User-based...')\n",
    "algo_KNN_U.fit(trainset)\n",
    "\n",
    "print('\\n','SVD...')\n",
    "algo_SVD.fit(trainset)\n",
    "\n",
    "print('\\n','Fin entraînement!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation des modèles \n",
      "\n",
      "RMSE: 1.3700\n",
      "NormalPredictor : 1.3700431765306664 \n",
      "\n",
      "RMSE: 0.8670\n",
      "KNN Item-based : 0.8670141347697389 \n",
      "\n",
      "RMSE: 0.8422\n",
      "KNN User-based : 0.8421772194208027 \n",
      "\n",
      "RMSE: 0.8112\n",
      "SVD : 0.8111849663674929 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation des modèles\n",
    "from surprise import accuracy\n",
    "\n",
    "print('Evaluation des modèles','\\n')\n",
    "\n",
    "pred_NP = algo_NP.test(testset)\n",
    "acc_NP = accuracy.rmse(pred_NP)\n",
    "print('NormalPredictor :',acc_NP,'\\n')\n",
    "\n",
    "pred_KNN_I = algo_KNN_I.test(testset)\n",
    "acc_KNN_I = accuracy.rmse(pred_KNN_I)\n",
    "print('KNN Item-based :',acc_KNN_I,'\\n')\n",
    "\n",
    "pred_KNN_U = algo_KNN_U.test(testset)\n",
    "acc_KNN_U = accuracy.rmse(pred_KNN_U)\n",
    "print('KNN User-based :',acc_KNN_U,'\\n')\n",
    "\n",
    "pred_SVD = algo_SVD.test(testset)\n",
    "acc_SVD = accuracy.rmse(pred_SVD)\n",
    "print('SVD :',acc_SVD,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des prédictions autour de la moyenne ( 3.7 / 5 ) : \n",
      "\n",
      "Entre 0.5 et 1.5:  0.3  %\n",
      "Entre 1.5 et 2.9:  9.98  %\n",
      "Entre 2.9 et 3.4:  18.5  %\n",
      "Entre 3.4 et 3.9:  32.4  %\n",
      "Entre 3.9 et 4.4:  29.24  %\n",
      "Entre 4.4 et 5.0:  9.58  %\n"
     ]
    }
   ],
   "source": [
    "# Répartition des prédictions du meilleur modèle\n",
    "p_0 = []\n",
    "p_1 = []\n",
    "p_2 = []\n",
    "p_3 = []\n",
    "p_4 = []\n",
    "p_5 = []\n",
    "\n",
    "for i in list(range(len(pred_SVD))):\n",
    "    if pred_SVD[i][3] < 1.5:\n",
    "        p_0.append(pred_SVD[i][3])\n",
    "    elif pred_SVD[i][3] <= 2.9:\n",
    "        p_1.append(pred_SVD[i][3])\n",
    "    elif pred_SVD[i][3] <= 3.4:\n",
    "        p_2.append(pred_SVD[i][3])\n",
    "    elif pred_SVD[i][3] <= 3.9:\n",
    "        p_3.append(pred_SVD[i][3])\n",
    "    elif pred_SVD[i][3] <= 4.4:\n",
    "        p_4.append(pred_SVD[i][3])\n",
    "    elif pred_SVD[i][3] > 4.4:\n",
    "        p_5.append(pred_SVD[i][3])\n",
    "print('Répartition des prédictions autour de la moyenne (', round(df.rating.mean(),1),'/ 5 ) :','\\n')\n",
    "print('Entre 0.5 et 1.5: ',round(len(p_0)/len(testset)*100,2),' %')\n",
    "print('Entre 1.5 et 2.9: ',round(len(p_1)/len(testset)*100,2),' %')\n",
    "print('Entre 2.9 et 3.4: ',round(len(p_2)/len(testset)*100,2),' %')\n",
    "print('Entre 3.4 et 3.9: ',round(len(p_3)/len(testset)*100,2),' %')\n",
    "print('Entre 3.9 et 4.4: ',round(len(p_4)/len(testset)*100,2),' %')\n",
    "print('Entre 4.4 et 5.0: ',round(len(p_5)/len(testset)*100,2),' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du meilleur modèle et de ses prédictions\n",
    "\n",
    "import time\n",
    "import os\n",
    "from surprise.dump import dump\n",
    "\n",
    "date = time.strftime('%y%m%d-%Hh%Mm%S', time.localtime())\n",
    "file_name = 'AlgoEval_BM_' + algo_SVD.__class__.__name__ + '_' + date\n",
    "#file_name += '-fold{0}'.format(fold_i + 1)\n",
    "dump_dir = os.path.expanduser('~') + '/Desktop/DS-Bootcamp/Projet/Projet-RS_Films/Model/'\n",
    "file_name = os.path.join(dump_dir, file_name)\n",
    "\n",
    "dump(file_name, pred_SVD, algo_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2858, 115430, 5.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.711222738997067"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation d'une prédiction en particulier (exple : User 2858 sur Movie 115430)\n",
    "\n",
    "prediction = algo_SVD.predict(2858,115430)\n",
    "prediction.est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur modèle avant optimisation semble être le modèle SVD, suivi de près par le modèle avec une approche de type KNN (User-Based). On envisage donc d'optimiser ces 2 modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Optimisation KNN User-Based (parameters tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210582, 3) <surprise.dataset.DatasetAutoFolds object at 0x00000137F32E6460>\n"
     ]
    }
   ],
   "source": [
    "# Chargement du Dataset\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "df = pd.read_csv(r\"Dataset\\data_t0f.csv\")\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df, reader)\n",
    "\n",
    "print(df.shape, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Entraînement / Validation en vue du GridSearch\n",
    "\n",
    "# Mélange des données\n",
    "import random\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "# Train = 80% , Test = 20%\n",
    "threshold = int(.8 * len(raw_ratings))\n",
    "Train_raw_ratings = raw_ratings[:threshold]\n",
    "Test_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = Train_raw_ratings  # data is now the Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Entrainement de la grille par CrossValidation sur le Trainset (NbCombinations x NbCV)\n",
    "param_grid = {'k': [10, 20, 50, 100], 'min_k': [1,2], 'sim_options': \n",
    "                                          {'name': ['msd', 'cosine'],\n",
    "                                            'min_support': [1,2],\n",
    "                                              'user_based': [True,False]}\n",
    "             }\n",
    "grid_search = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=5, n_jobs = -1)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 0.8384364965819039}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': {'k': 20,\n",
       "  'min_k': 2,\n",
       "  'sim_options': {'name': 'msd', 'min_support': 2, 'user_based': True}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(grid_search.cv_results)\n",
    "best_results_KNNBasic_t0f = results_df[results_df['rank_test_rmse'] < 10][['mean_test_rmse','std_test_rmse','rank_test_rmse','mean_fit_time','mean_test_time','param_k','param_min_k','param_sim_options']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS FOR KNNMeans\n",
    "#results_df.to_csv(r'Model\\All_GSresults_KNNBasic_t0f_210314.csv', index = False)\n",
    "#best_results_KNNBasic_t0f.to_csv(r'Model\\Best_GSresults_KNNMeans_t0f_210314.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>param_k</th>\n",
       "      <th>param_min_k</th>\n",
       "      <th>param_sim_options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840760</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>7</td>\n",
       "      <td>1.819134</td>\n",
       "      <td>10.425914</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'name': 'msd', 'min_support': 1, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.840206</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>6</td>\n",
       "      <td>2.052110</td>\n",
       "      <td>11.611143</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'name': 'msd', 'min_support': 2, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.840766</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>8</td>\n",
       "      <td>1.963145</td>\n",
       "      <td>10.724322</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'name': 'msd', 'min_support': 1, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.840174</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>5</td>\n",
       "      <td>2.028371</td>\n",
       "      <td>12.033615</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'name': 'msd', 'min_support': 2, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.838817</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>3</td>\n",
       "      <td>1.989877</td>\n",
       "      <td>12.904284</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'name': 'msd', 'min_support': 1, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.838469</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>2</td>\n",
       "      <td>1.737153</td>\n",
       "      <td>11.936274</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'name': 'msd', 'min_support': 2, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>4</td>\n",
       "      <td>1.847259</td>\n",
       "      <td>12.047775</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'name': 'msd', 'min_support': 1, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.838436</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.673923</td>\n",
       "      <td>11.868255</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'name': 'msd', 'min_support': 2, 'user_based'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.850727</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>9</td>\n",
       "      <td>1.716608</td>\n",
       "      <td>14.564842</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'name': 'msd', 'min_support': 2, 'user_based'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_rmse  std_test_rmse  rank_test_rmse  mean_fit_time  \\\n",
       "0         0.840760       0.003445               7       1.819134   \n",
       "1         0.840206       0.003394               6       2.052110   \n",
       "4         0.840766       0.003424               8       1.963145   \n",
       "5         0.840174       0.003417               5       2.028371   \n",
       "8         0.838817       0.003665               3       1.989877   \n",
       "9         0.838469       0.003666               2       1.737153   \n",
       "12        0.838824       0.003643               4       1.847259   \n",
       "13        0.838436       0.003692               1       1.673923   \n",
       "21        0.850727       0.003938               9       1.716608   \n",
       "\n",
       "    mean_test_time  param_k  param_min_k  \\\n",
       "0        10.425914       10            1   \n",
       "1        11.611143       10            1   \n",
       "4        10.724322       10            2   \n",
       "5        12.033615       10            2   \n",
       "8        12.904284       20            1   \n",
       "9        11.936274       20            1   \n",
       "12       12.047775       20            2   \n",
       "13       11.868255       20            2   \n",
       "21       14.564842       50            2   \n",
       "\n",
       "                                    param_sim_options  \n",
       "0   {'name': 'msd', 'min_support': 1, 'user_based'...  \n",
       "1   {'name': 'msd', 'min_support': 2, 'user_based'...  \n",
       "4   {'name': 'msd', 'min_support': 1, 'user_based'...  \n",
       "5   {'name': 'msd', 'min_support': 2, 'user_based'...  \n",
       "8   {'name': 'msd', 'min_support': 1, 'user_based'...  \n",
       "9   {'name': 'msd', 'min_support': 2, 'user_based'...  \n",
       "12  {'name': 'msd', 'min_support': 1, 'user_based'...  \n",
       "13  {'name': 'msd', 'min_support': 2, 'user_based'...  \n",
       "21  {'name': 'msd', 'min_support': 2, 'user_based'...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_KNNBasic_t0f.head(10)\n",
    "#best_results_KNNMeans_t0f['param_sim_options'].astype(str).str.split(',',expand=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algo with best params\n",
    "algo = grid_search.best_estimator['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x137f266d0d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain on the whole Trainset\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased accuracy on Trainset,   RMSE: 0.6553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6553469703170417"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute biased accuracy on Trainset\n",
    "from surprise import accuracy\n",
    "\n",
    "predictions = algo.test(trainset.build_testset())\n",
    "print('Biased accuracy on Trainset,', end='   ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on Testset, RMSE: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8285714310786031"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute unbiased accuracy on Testset\n",
    "testset = data.construct_testset(Test_raw_ratings)\n",
    "predictions = algo.test(testset)\n",
    "print('Unbiased accuracy on Testset,', end=' ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from surprise.dump import dump\n",
    "\n",
    "date = time.strftime('%y%m%d-%Hh%Mm%S', time.localtime())\n",
    "file_name = 'AlgoEval_BP_KNN_' + algo.__class__.__name__ + '_' + date\n",
    "#file_name += '-fold{0}'.format(fold_i + 1)\n",
    "dump_dir = os.path.expanduser('~') + '/Desktop/DS-Bootcamp/Projet/Projet-RS_Films/Model/'\n",
    "file_name = os.path.join(dump_dir, file_name)\n",
    "\n",
    "dump(file_name, predictions, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approche User-Based est bien meilleure que l'approche Item-Based, et la RMSE est légèrement améliorée suite à l'optimisation effectuée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Optimisation Matrix Factorisation SVD (parameters tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du Dataset\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "df = pd.read_csv(r\"Dataset\\data_t0f.csv\")\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df, reader)\n",
    "\n",
    "print(df.shape, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Entraînement / Validation en vue du GridSearch\n",
    "\n",
    "# Mélange des données\n",
    "import random\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "# Train = 80% , Test = 20%\n",
    "threshold = int(.8 * len(raw_ratings))\n",
    "Train_raw_ratings = raw_ratings[:threshold]\n",
    "Test_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = Train_raw_ratings  # data is now the Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Entrainement de la grille par CrossValidation sur le Trainset (NbCombinations x NbCV)\n",
    "param_grid = {'n_factors': [50,80,100,120,150,200], 'init_mean': [0,1.0,2.5], 'init_std_dev': [0.05,0.1,0.2,0.5], 'lr_all': [0.002,0.005,0.01,0.05,0.1], 'reg_all': [0.02,0.05,0.1,0.5,1]}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['mae', 'rmse', 'fcp'], cv=5, n_jobs = -1)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.59257003938627,\n",
       " 'rmse': 0.7939014637603912,\n",
       " 'fcp': 0.7147300892988626}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': {'n_factors': 200,\n",
       "  'init_mean': 0,\n",
       "  'init_std_dev': 0.05,\n",
       "  'lr_all': 0.01,\n",
       "  'reg_all': 0.05},\n",
       " 'rmse': {'n_factors': 200,\n",
       "  'init_mean': 0,\n",
       "  'init_std_dev': 0.05,\n",
       "  'lr_all': 0.01,\n",
       "  'reg_all': 0.05},\n",
       " 'fcp': {'n_factors': 200,\n",
       "  'init_mean': 0,\n",
       "  'init_std_dev': 0.05,\n",
       "  'lr_all': 0.05,\n",
       "  'reg_all': 0.05}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>mean_test_fcp</th>\n",
       "      <th>std_test_fcp</th>\n",
       "      <th>rank_test_fcp</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>param_n_factors</th>\n",
       "      <th>param_init_mean</th>\n",
       "      <th>param_init_std_dev</th>\n",
       "      <th>param_lr_all</th>\n",
       "      <th>param_reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.595234</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>11</td>\n",
       "      <td>0.797043</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>5</td>\n",
       "      <td>0.710177</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>1770</td>\n",
       "      <td>23.155665</td>\n",
       "      <td>0.793278</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.593797</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>4</td>\n",
       "      <td>0.795584</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>4</td>\n",
       "      <td>0.712106</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>1794</td>\n",
       "      <td>27.139808</td>\n",
       "      <td>0.790885</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>0.594398</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>8</td>\n",
       "      <td>0.798341</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.711514</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>1790</td>\n",
       "      <td>30.878208</td>\n",
       "      <td>0.792082</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0.593755</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>3</td>\n",
       "      <td>0.795261</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>3</td>\n",
       "      <td>0.712763</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>1795</td>\n",
       "      <td>31.324614</td>\n",
       "      <td>0.788092</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.594102</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>5</td>\n",
       "      <td>0.798269</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>8</td>\n",
       "      <td>0.711968</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>1793</td>\n",
       "      <td>37.155618</td>\n",
       "      <td>0.797068</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.592666</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794075</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>2</td>\n",
       "      <td>0.713621</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>1798</td>\n",
       "      <td>37.512264</td>\n",
       "      <td>0.797866</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>0.594298</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>7</td>\n",
       "      <td>0.797585</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>6</td>\n",
       "      <td>0.711425</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>1789</td>\n",
       "      <td>47.552210</td>\n",
       "      <td>0.806443</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>0.592570</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793901</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714056</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1799</td>\n",
       "      <td>47.264778</td>\n",
       "      <td>0.807042</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>0.595267</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>12</td>\n",
       "      <td>0.798174</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714730</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>1800</td>\n",
       "      <td>47.155470</td>\n",
       "      <td>0.794076</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_test_mae  std_test_mae  rank_test_mae  mean_test_rmse  \\\n",
       "311        0.595234      0.004427             11        0.797043   \n",
       "611        0.593797      0.004002              4        0.795584   \n",
       "910        0.594398      0.004817              8        0.798341   \n",
       "911        0.593755      0.004345              3        0.795261   \n",
       "1210       0.594102      0.004536              5        0.798269   \n",
       "1211       0.592666      0.004277              2        0.794075   \n",
       "1510       0.594298      0.004069              7        0.797585   \n",
       "1511       0.592570      0.004357              1        0.793901   \n",
       "1516       0.595267      0.004825             12        0.798174   \n",
       "\n",
       "      std_test_rmse  rank_test_rmse  mean_test_fcp  std_test_fcp  \\\n",
       "311        0.005752               5       0.710177      0.003857   \n",
       "611        0.005370               4       0.712106      0.003154   \n",
       "910        0.006250               9       0.711514      0.003215   \n",
       "911        0.005892               3       0.712763      0.003585   \n",
       "1210       0.006034               8       0.711968      0.003726   \n",
       "1211       0.005791               2       0.713621      0.003318   \n",
       "1510       0.005535               6       0.711425      0.002692   \n",
       "1511       0.005740               1       0.714056      0.003636   \n",
       "1516       0.006355               7       0.714730      0.003167   \n",
       "\n",
       "      rank_test_fcp  mean_fit_time  mean_test_time  param_n_factors  \\\n",
       "311            1770      23.155665        0.793278               80   \n",
       "611            1794      27.139808        0.790885              100   \n",
       "910            1790      30.878208        0.792082              120   \n",
       "911            1795      31.324614        0.788092              120   \n",
       "1210           1793      37.155618        0.797068              150   \n",
       "1211           1798      37.512264        0.797866              150   \n",
       "1510           1789      47.552210        0.806443              200   \n",
       "1511           1799      47.264778        0.807042              200   \n",
       "1516           1800      47.155470        0.794076              200   \n",
       "\n",
       "      param_init_mean  param_init_std_dev  param_lr_all  param_reg_all  \n",
       "311               0.0                0.05          0.01           0.05  \n",
       "611               0.0                0.05          0.01           0.05  \n",
       "910               0.0                0.05          0.01           0.02  \n",
       "911               0.0                0.05          0.01           0.05  \n",
       "1210              0.0                0.05          0.01           0.02  \n",
       "1211              0.0                0.05          0.01           0.05  \n",
       "1510              0.0                0.05          0.01           0.02  \n",
       "1511              0.0                0.05          0.01           0.05  \n",
       "1516              0.0                0.05          0.05           0.05  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(grid_search.cv_results)\n",
    "results_df.head()\n",
    "best_results_SVD_t0f = results_df[results_df['rank_test_rmse'] < 10][['mean_test_mae','std_test_mae','rank_test_mae','mean_test_rmse','std_test_rmse','rank_test_rmse','mean_test_fcp','std_test_fcp','rank_test_fcp','mean_fit_time','mean_test_time','param_n_factors','param_init_mean','param_init_std_dev','param_lr_all','param_reg_all']]\n",
    "best_results_SVD_t0f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS FOR SVD GRID SEARCH\n",
    "results_df.to_csv(r'Model\\All_GSresults_SVD_t0f_210315.csv', index = False)\n",
    "best_results_SVD_t0f.to_csv(r'Model\\Best_GSresults_SVD_t0f_210315.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best parameters\n",
    "algo = grid_search.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x28325a7b910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain on the whole Trainset\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased accuracy on Trainset,   RMSE: 0.5902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5902481765198406"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute biased accuracy on Trainset\n",
    "from surprise import accuracy\n",
    "\n",
    "predictions = algo.test(trainset.build_testset())\n",
    "print('Biased accuracy on Trainset,', end='   ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on Testset, RMSE: 0.7794\n",
      "MAE:  0.5811\n",
      "FCP:  0.7282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7281971298916068"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute unbiased accuracy on Testset\n",
    "\n",
    "testset = data.construct_testset(Test_raw_ratings)\n",
    "predictions = algo.test(testset)\n",
    "print('Unbiased accuracy on Testset,', end=' ')\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "accuracy.fcp(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16\n",
      "4.07\n",
      "8.46\n",
      "55.93\n",
      "25.62\n",
      "5.76\n"
     ]
    }
   ],
   "source": [
    "p_0 = []\n",
    "p_1 = []\n",
    "p_2 = []\n",
    "p_3 = []\n",
    "p_4 = []\n",
    "p_5 = []\n",
    "\n",
    "for i in list(range(len(predictions))):\n",
    "    if predictions[i][3] <= 1.25:\n",
    "        p_0.append(predictions[i][3])\n",
    "    elif predictions[i][3] <= 2.5:\n",
    "        p_1.append(predictions[i][3])\n",
    "    elif predictions[i][3] <= 3:\n",
    "        p_2.append(predictions[i][3])\n",
    "    elif predictions[i][3] <= 4:\n",
    "        p_3.append(predictions[i][3])\n",
    "    elif predictions[i][3] <= 4.5:\n",
    "        p_4.append(predictions[i][3])\n",
    "    elif predictions[i][3] > 4.5:\n",
    "        p_5.append(predictions[i][3])\n",
    "print(round(len(p_0)/len(testset)*100,2))\n",
    "print(round(len(p_1)/len(testset)*100,2))\n",
    "print(round(len(p_2)/len(testset)*100,2))\n",
    "print(round(len(p_3)/len(testset)*100,2))\n",
    "print(round(len(p_4)/len(testset)*100,2))\n",
    "print(round(len(p_5)/len(testset)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dump has been saved as file C:\\Users\\Client/Desktop/DS-Bootcamp/Projet/Projet-RS_Films/Model/210315-21h47m15-SVD_BP_Vt0f_t\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from surprise.dump import dump\n",
    "\n",
    "date = time.strftime('%y%m%d-%Hh%Mm%S', time.localtime())\n",
    "file_name = date + '-' + algo.__class__.__name__ + '_BP_Vt0f'\n",
    "#file_name += '-fold{0}'.format(fold_i + 1)\n",
    "dump_dir = os.path.expanduser('~') + '/Desktop/DS-Bootcamp/Projet/Projet-RS_Films/Model/'\n",
    "file_name = os.path.join(dump_dir, file_name)\n",
    "\n",
    "dump(file_name, predictions, algo, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimisation effectuée sur l'algorithme SVD (1800 combinaisons de paramètres testées : 10h d'analyse / évaluation) a permis d'obtenir une meilleure mesure de prédiction (RMSE sous la barre des 0,80 => 0,7794 exactement). On sauvegarde ce dernier modèle optimisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
